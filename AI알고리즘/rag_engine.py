from vector_db_loader import load_vectordb
from db_utils import get_hotels_by_region, build_context_from_sql
from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain

# âœ… í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ì ì •ì˜ ìŠ¤íƒ€ì¼ ë°˜ì˜)
system_template = """
ë‹¹ì‹ ì€ ê³ ë ¹ì ë° ì¥ì• ì¸ì„ ìœ„í•œ ìˆ™ì†Œ ì¶”ì²œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í›„ë³´ ìˆ™ì†Œ ëª©ë¡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì½ê³ , **ê°€ì¥ ì ì ˆí•œ ìˆ™ì†Œ 3ê³³ì„ ì¶”ì²œ**í•´ ì£¼ì„¸ìš”.
ì¶”ì²œí•  ë•ŒëŠ” ë°˜ë“œì‹œ **contextì— ì£¼ì–´ì§„ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨**í•´ì•¼ í•˜ë©°, **ë‹¤ë¥¸ ì •ë³´ëŠ” ì ˆëŒ€ ì°¸ê³ í•˜ì§€ ë§ˆì„¸ìš”.**

[ì¶”ì²œ ê¸°ì¤€]
- ê³ ë ¹ì, íœ ì²´ì–´ ì´ìš©ì, ì‹œê°ì¥ì• ì¸ ë“± **ì´ë™ ë˜ëŠ” ê°ê°ì— ì œì•½ì´ ìˆëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­**ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
- ì§ˆë¬¸ì— ëª…ì‹œëœ ì¡°ê±´(ì˜ˆ: íœ ì²´ì–´, ì—˜ë¦¬ë² ì´í„°, ì ì ì•ˆë‚´íŒ ë“±)ì— **ì •í™•íˆ ëŒ€ì‘í•˜ëŠ” ìˆ™ì†Œ**ë¥¼ ì„ ë³„í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ìˆ™ì†Œ **3ê³³ì„ ì¶”ì²œí•´ì•¼ í•˜ë©°, 3ê°œ ë¯¸ë§Œ ë˜ëŠ” ì´ˆê³¼ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.**
- ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ ì˜ˆì‹œë¥¼ **ì •í™•íˆ ê·¸ëŒ€ë¡œ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.**

ì¶œë ¥ ì˜ˆì‹œ (ì •í™•íˆ ì´ í˜•ì‹ì´ì–´ì•¼ í•¨):

1. ìˆ™ì†Œëª…: ì†ì´ˆë°”ë‹¤í˜¸í…”
   ì£¼ì†Œ: í•´ì•ˆë¡œ 406ë²ˆê¸¸ 17

2. ìˆ™ì†Œëª…: ì„¤ì•…íê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤
   ì£¼ì†Œ: ì¤‘ì•™ë¡œ 233

3. ìˆ™ì†Œëª…: ìŠ¤ì¹´ì´ë² ì´ ê²½í¬
   ì£¼ì†Œ: ê²½í¬ë¡œ 476
"""

system_msg = SystemMessagePromptTemplate.from_template(system_template)
human_msg = HumanMessagePromptTemplate.from_template("{context}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{question}")
chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])
llm_chain = LLMChain(prompt=chat_prompt, llm=ChatOpenAI(model_name="gpt-4o", temperature=0.7))

vectordb = load_vectordb()

# âœ¨ ìµœì¢… ì¶”ì²œ í•¨ìˆ˜ (ì§€ì—­ ë²¡í„° í•„í„°ë§ í¬í•¨)
def recommend_accommodations(user_query, region_name, top_k=5):
    # ğŸ” ì§€ì—­ í•„í„°ë§ì„ ë²¡í„° ê²€ìƒ‰ì— ì§ì ‘ ì ìš©
    filtered_docs = vectordb.similarity_search(
        user_query,
        k=top_k,
        filter={"ì‹œêµ°êµ¬ëª…": region_name}
    )
    print("[DEBUG] ğŸ“ ì§€ì—­ ë²¡í„° í•„í„° ê²€ìƒ‰ ê²°ê³¼:", len(filtered_docs))

    ì¶”ì²œìˆ™ì†Œë“¤ = list({doc.metadata["ìˆ™ì†Œëª…"] for doc in filtered_docs})
    print("[DEBUG] âœ… ìµœì¢… ì¶”ì²œ ëŒ€ìƒ ìˆ™ì†Œ:", ì¶”ì²œìˆ™ì†Œë“¤)

    context = build_context_from_sql(ì¶”ì²œìˆ™ì†Œë“¤)
    print("[DEBUG] ğŸ“¦ ìƒì„±ëœ context ë‚´ìš©:\n", context)

    result = llm_chain.run({"context": context, "question": user_query})
    print("[DEBUG] ğŸ¤– LLM ì‘ë‹µ ì›ë¬¸:\n", repr(result))
    return result
