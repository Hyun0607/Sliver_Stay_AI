# -*- coding: utf-8 -*-
"""CapStone_RAG(예상질의)_평가용.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z3rBtt86E2M9fVbnaEwmlLLPRWAU50_8
"""

!pip install -U langchain langchain-community
!pip install chromadb
!pip install tiktoken

# ✅ 1. 필수 라이브러리
import os
import pandas as pd
from sqlalchemy import create_engine, text
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain.schema import Document

# ✅ GCP PostgreSQL 연결
DB_USER = "capstone"
DB_PASSWORD = "qzwxec7462!"
DB_HOST = "34.64.95.231"
DB_PORT = "5432"
DB_NAME = "sliverstay"
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = create_engine(DATABASE_URL)

# ✅ 2. OpenAI API 키
os.environ["OPENAI_API_KEY"] = "sk-...."  # 본인의 키로 교체

# 데이터 불러오기
df = pd.read_csv("VectorDB_캡스톤_ver2.csv").fillna("")

# 문서 리스트 구성
docs = []
for _, row in df.iterrows():
    숙소명 = row["숙소명"]
    시군구명 = row["시군구명"]
    질문들 = [row[f"질문{i}"] for i in range(1, 6) if row[f"질문{i}"].strip()]
    for 질문 in 질문들:
        doc = Document(page_content=질문, metadata={"숙소명": 숙소명, "시군구명": 시군구명})
        docs.append(doc)

# ✨ 8. VectorDB 저장 (Chroma + Embedding)
embedding = OpenAIEmbeddings()
vectordb = Chroma.from_documents(docs, embedding, persist_directory="./chroma_db2")
vectordb.persist()
print("✅ VectorDB 저장 완료: ./chroma_db2")

# ✅ 5. 메시지 프롬프트 구성 (3개 추천 전용)
system_template =  """
당신은 고령자 및 장애인을 위한 숙소 추천 도우미입니다.

아래는 후보 숙소 목록입니다. 사용자의 질문을 읽고, **가장 적절한 숙소 3곳을 추천**해 주세요.
추천할 때는 반드시 **context에 주어진 정보만을 바탕으로 판단**해야 하며, **다른 정보는 절대 참고하지 마세요.**
context 중에서도 **숙소 설명**을 우선적으로 참고하세요.

[추천 기준]
- 고령자, 휠체어 이용자, 시각장애인 등 **이동 또는 감각에 제약이 있는 사용자의 요구사항**을 우선적으로 고려하세요.
- 질문에 명시된 조건(예: 휠체어, 엘리베이터, 점자 안내판 등)에 **정확히 대응하는 숙소**를 선별하세요.
- 반드시 숙소 **3곳을 추천해야 하며**, 3개 미만일 경우 추천된 숙소만 출력하세요
- 출력 형식은 아래 예시를 **정확히 그대로 따라야 합니다.**

출력 예시 (정확히 이 형식이어야 함):

1. 씨마크호텔
2. 강릉관광호텔
3. 롯데리조트 속초
"""
system_msg_one = SystemMessagePromptTemplate.from_template(system_template)
human_msg_one = HumanMessagePromptTemplate.from_template("{context}\n\n[사용자 질문]\n{question}")
chat_prompt_one = ChatPromptTemplate.from_messages([system_msg_one, human_msg_one])
llm_one = ChatOpenAI(model_name="gpt-4o", temperature=0.7)
llm_chain = LLMChain(prompt=chat_prompt_one, llm=llm_one)

# PostgreSQL(GCP)에서 특정 지역(시군구명) 숙소명 추출 - 지역 필터링
def get_hotels_by_region(region_name):
    with engine.connect() as conn:
        query = text("SELECT 숙소명 FROM 숙소정보 WHERE 시군구명 = :region")
        result = conn.execute(query, {"region": region_name})
        return {row[0] for row in result.fetchall()}

def build_context_from_sql(hotel_names):
    context = ""
    with engine.connect() as conn:
        for name in hotel_names:
            name = name.strip()
            query = text("SELECT 주소, 장애인편의시설, 숙소설명 FROM 숙소정보 WHERE 숙소명 = :name")
            result = conn.execute(query, {"name": name}).fetchone()
            if not result:
                print(f"[WARN] '{name}'에 대한 숙소 정보가 없습니다.")
                continue
            주소, 장애인편의시설, 숙소설명 = result
            if 장애인편의시설 == "X":
                장애인편의시설 = "편의시설 정보 없음"
            context += (
                f"숙소명: {name}\n"
                f"주소: {주소}\n"
                f"편의시설: {장애인편의시설}\n"
                f"설명: {숙소설명}\n\n"
            )
    return context.strip()

# ✨ 12. 최종 추천 함수 (지역 벡터 필터링 포함)
def recommend_accommodations(user_query, region_name, top_k=5):
    # 🔍 지역 필터링을 벡터 검색에 직접 적용
    filtered_docs = vectordb.similarity_search(
        user_query,
        k=top_k,
        filter={"시군구명": region_name}
    )
    print("[DEBUG] 📍 지역 벡터 필터 검색 결과:", len(filtered_docs))

    추천숙소들 = list({doc.metadata["숙소명"] for doc in filtered_docs})
    print("[DEBUG] ✅ 최종 추천 대상 숙소:", 추천숙소들)

    context = build_context_from_sql(추천숙소들)
    print("[DEBUG] 📦 생성된 context 내용:\n", context)

    result = llm_chain.run({"context": context, "question": user_query})
    print("[DEBUG] 🤖 LLM 응답 원문:\n", repr(result))
    return result

# 추천 결과 확인
query = "춘천에 엘리베이터 이동 가능한 숙소가 있나요?"
지역명 = "춘천시"

print("🤖 AI 응답:\n", recommend_accommodations(query, 지역명))

import pandas as pd
import re

# ✅ 1. 평가용 질의 불러오기
eval_df = pd.read_csv("속초시_평가질의_최종100개.csv")

# ✅ 2. 응답 텍스트에서 숙소명 파싱 함수
def parse_recommendation(response_text):
    lines = response_text.strip().splitlines()
    result = []
    for line in lines:
        match = re.match(r"\d+\.\s*(숙소명:)?\s*(.+)", line.strip())
        if match:
            result.append(match.group(2).strip())
    while len(result) < 3:
        result.append("추천 실패")
    return result[:3]

# ✅ 3. 자동 평가 실행 루프
auto_results = []

지역명 = "속초시"  # 평가 대상 지역

for idx, row in eval_df.iterrows():
    query = row["질의"]

    try:
        response = recommend_accommodations(user_query=query, region_name=지역명, top_k=5)
        top3 = parse_recommendation(response)
    except Exception as e:
        print(f"[{idx}] 에러 발생: {e}")
        top3 = ["추천 실패", "추천 실패", "추천 실패"]

    auto_results.append({
        "질의": query,
        "포함핵심어": row["포함핵심어"],
        "포함개수": row["포함개수"],
        "추천_숙소1": top3[0],
        "추천_숙소2": top3[1],
        "추천_숙소3": top3[2]
    })

# ✅ 4. 평가 결과 저장
result_df = pd.DataFrame(auto_results)
result_df.to_csv("평가결과_춘천시_지역필터2.csv", index=False, encoding="utf-8-sig")
print("✅ 저장 완료: 평가결과_춘천시_지역필터2.csv")