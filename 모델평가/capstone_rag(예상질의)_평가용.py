# -*- coding: utf-8 -*-
"""CapStone_RAG(ì˜ˆìƒì§ˆì˜)_í‰ê°€ìš©.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z3rBtt86E2M9fVbnaEwmlLLPRWAU50_8
"""

!pip install -U langchain langchain-community
!pip install chromadb
!pip install tiktoken

# âœ… 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import pandas as pd
from sqlalchemy import create_engine, text
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain.schema import Document

# âœ… GCP PostgreSQL ì—°ê²°
DB_USER = "capstone"
DB_PASSWORD = "qzwxec7462!"
DB_HOST = "34.64.95.231"
DB_PORT = "5432"
DB_NAME = "sliverstay"
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = create_engine(DATABASE_URL)

# âœ… 2. OpenAI API í‚¤
os.environ["OPENAI_API_KEY"] = "sk-...."  # ë³¸ì¸ì˜ í‚¤ë¡œ êµì²´

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("VectorDB_ìº¡ìŠ¤í†¤_ver2.csv").fillna("")

# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
docs = []
for _, row in df.iterrows():
    ìˆ™ì†Œëª… = row["ìˆ™ì†Œëª…"]
    ì‹œêµ°êµ¬ëª… = row["ì‹œêµ°êµ¬ëª…"]
    ì§ˆë¬¸ë“¤ = [row[f"ì§ˆë¬¸{i}"] for i in range(1, 6) if row[f"ì§ˆë¬¸{i}"].strip()]
    for ì§ˆë¬¸ in ì§ˆë¬¸ë“¤:
        doc = Document(page_content=ì§ˆë¬¸, metadata={"ìˆ™ì†Œëª…": ìˆ™ì†Œëª…, "ì‹œêµ°êµ¬ëª…": ì‹œêµ°êµ¬ëª…})
        docs.append(doc)

# âœ¨ 8. VectorDB ì €ì¥ (Chroma + Embedding)
embedding = OpenAIEmbeddings()
vectordb = Chroma.from_documents(docs, embedding, persist_directory="./chroma_db2")
vectordb.persist()
print("âœ… VectorDB ì €ì¥ ì™„ë£Œ: ./chroma_db2")

# âœ… 5. ë©”ì‹œì§€ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (3ê°œ ì¶”ì²œ ì „ìš©)
system_template =  """
ë‹¹ì‹ ì€ ê³ ë ¹ì ë° ì¥ì• ì¸ì„ ìœ„í•œ ìˆ™ì†Œ ì¶”ì²œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í›„ë³´ ìˆ™ì†Œ ëª©ë¡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì½ê³ , **ê°€ì¥ ì ì ˆí•œ ìˆ™ì†Œ 3ê³³ì„ ì¶”ì²œ**í•´ ì£¼ì„¸ìš”.
ì¶”ì²œí•  ë•ŒëŠ” ë°˜ë“œì‹œ **contextì— ì£¼ì–´ì§„ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨**í•´ì•¼ í•˜ë©°, **ë‹¤ë¥¸ ì •ë³´ëŠ” ì ˆëŒ€ ì°¸ê³ í•˜ì§€ ë§ˆì„¸ìš”.**
context ì¤‘ì—ì„œë„ **ìˆ™ì†Œ ì„¤ëª…**ì„ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì„¸ìš”.

[ì¶”ì²œ ê¸°ì¤€]
- ê³ ë ¹ì, íœ ì²´ì–´ ì´ìš©ì, ì‹œê°ì¥ì• ì¸ ë“± **ì´ë™ ë˜ëŠ” ê°ê°ì— ì œì•½ì´ ìˆëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­**ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
- ì§ˆë¬¸ì— ëª…ì‹œëœ ì¡°ê±´(ì˜ˆ: íœ ì²´ì–´, ì—˜ë¦¬ë² ì´í„°, ì ì ì•ˆë‚´íŒ ë“±)ì— **ì •í™•íˆ ëŒ€ì‘í•˜ëŠ” ìˆ™ì†Œ**ë¥¼ ì„ ë³„í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ìˆ™ì†Œ **3ê³³ì„ ì¶”ì²œí•´ì•¼ í•˜ë©°**, 3ê°œ ë¯¸ë§Œì¼ ê²½ìš° ì¶”ì²œëœ ìˆ™ì†Œë§Œ ì¶œë ¥í•˜ì„¸ìš”
- ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ ì˜ˆì‹œë¥¼ **ì •í™•íˆ ê·¸ëŒ€ë¡œ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.**

ì¶œë ¥ ì˜ˆì‹œ (ì •í™•íˆ ì´ í˜•ì‹ì´ì–´ì•¼ í•¨):

1. ì”¨ë§ˆí¬í˜¸í…”
2. ê°•ë¦‰ê´€ê´‘í˜¸í…”
3. ë¡¯ë°ë¦¬ì¡°íŠ¸ ì†ì´ˆ
"""
system_msg_one = SystemMessagePromptTemplate.from_template(system_template)
human_msg_one = HumanMessagePromptTemplate.from_template("{context}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{question}")
chat_prompt_one = ChatPromptTemplate.from_messages([system_msg_one, human_msg_one])
llm_one = ChatOpenAI(model_name="gpt-4o", temperature=0.7)
llm_chain = LLMChain(prompt=chat_prompt_one, llm=llm_one)

# PostgreSQL(GCP)ì—ì„œ íŠ¹ì • ì§€ì—­(ì‹œêµ°êµ¬ëª…) ìˆ™ì†Œëª… ì¶”ì¶œ - ì§€ì—­ í•„í„°ë§
def get_hotels_by_region(region_name):
    with engine.connect() as conn:
        query = text("SELECT ìˆ™ì†Œëª… FROM ìˆ™ì†Œì •ë³´ WHERE ì‹œêµ°êµ¬ëª… = :region")
        result = conn.execute(query, {"region": region_name})
        return {row[0] for row in result.fetchall()}

def build_context_from_sql(hotel_names):
    context = ""
    with engine.connect() as conn:
        for name in hotel_names:
            name = name.strip()
            query = text("SELECT ì£¼ì†Œ, ì¥ì• ì¸í¸ì˜ì‹œì„¤, ìˆ™ì†Œì„¤ëª… FROM ìˆ™ì†Œì •ë³´ WHERE ìˆ™ì†Œëª… = :name")
            result = conn.execute(query, {"name": name}).fetchone()
            if not result:
                print(f"[WARN] '{name}'ì— ëŒ€í•œ ìˆ™ì†Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            ì£¼ì†Œ, ì¥ì• ì¸í¸ì˜ì‹œì„¤, ìˆ™ì†Œì„¤ëª… = result
            if ì¥ì• ì¸í¸ì˜ì‹œì„¤ == "X":
                ì¥ì• ì¸í¸ì˜ì‹œì„¤ = "í¸ì˜ì‹œì„¤ ì •ë³´ ì—†ìŒ"
            context += (
                f"ìˆ™ì†Œëª…: {name}\n"
                f"ì£¼ì†Œ: {ì£¼ì†Œ}\n"
                f"í¸ì˜ì‹œì„¤: {ì¥ì• ì¸í¸ì˜ì‹œì„¤}\n"
                f"ì„¤ëª…: {ìˆ™ì†Œì„¤ëª…}\n\n"
            )
    return context.strip()

# âœ¨ 12. ìµœì¢… ì¶”ì²œ í•¨ìˆ˜ (ì§€ì—­ ë²¡í„° í•„í„°ë§ í¬í•¨)
def recommend_accommodations(user_query, region_name, top_k=5):
    # ğŸ” ì§€ì—­ í•„í„°ë§ì„ ë²¡í„° ê²€ìƒ‰ì— ì§ì ‘ ì ìš©
    filtered_docs = vectordb.similarity_search(
        user_query,
        k=top_k,
        filter={"ì‹œêµ°êµ¬ëª…": region_name}
    )
    print("[DEBUG] ğŸ“ ì§€ì—­ ë²¡í„° í•„í„° ê²€ìƒ‰ ê²°ê³¼:", len(filtered_docs))

    ì¶”ì²œìˆ™ì†Œë“¤ = list({doc.metadata["ìˆ™ì†Œëª…"] for doc in filtered_docs})
    print("[DEBUG] âœ… ìµœì¢… ì¶”ì²œ ëŒ€ìƒ ìˆ™ì†Œ:", ì¶”ì²œìˆ™ì†Œë“¤)

    context = build_context_from_sql(ì¶”ì²œìˆ™ì†Œë“¤)
    print("[DEBUG] ğŸ“¦ ìƒì„±ëœ context ë‚´ìš©:\n", context)

    result = llm_chain.run({"context": context, "question": user_query})
    print("[DEBUG] ğŸ¤– LLM ì‘ë‹µ ì›ë¬¸:\n", repr(result))
    return result

# ì¶”ì²œ ê²°ê³¼ í™•ì¸
query = "ì¶˜ì²œì— ì—˜ë¦¬ë² ì´í„° ì´ë™ ê°€ëŠ¥í•œ ìˆ™ì†Œê°€ ìˆë‚˜ìš”?"
ì§€ì—­ëª… = "ì¶˜ì²œì‹œ"

print("ğŸ¤– AI ì‘ë‹µ:\n", recommend_accommodations(query, ì§€ì—­ëª…))

import pandas as pd
import re

# âœ… 1. í‰ê°€ìš© ì§ˆì˜ ë¶ˆëŸ¬ì˜¤ê¸°
eval_df = pd.read_csv("ì†ì´ˆì‹œ_í‰ê°€ì§ˆì˜_ìµœì¢…100ê°œ.csv")

# âœ… 2. ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ìˆ™ì†Œëª… íŒŒì‹± í•¨ìˆ˜
def parse_recommendation(response_text):
    lines = response_text.strip().splitlines()
    result = []
    for line in lines:
        match = re.match(r"\d+\.\s*(ìˆ™ì†Œëª…:)?\s*(.+)", line.strip())
        if match:
            result.append(match.group(2).strip())
    while len(result) < 3:
        result.append("ì¶”ì²œ ì‹¤íŒ¨")
    return result[:3]

# âœ… 3. ìë™ í‰ê°€ ì‹¤í–‰ ë£¨í”„
auto_results = []

ì§€ì—­ëª… = "ì†ì´ˆì‹œ"  # í‰ê°€ ëŒ€ìƒ ì§€ì—­

for idx, row in eval_df.iterrows():
    query = row["ì§ˆì˜"]

    try:
        response = recommend_accommodations(user_query=query, region_name=ì§€ì—­ëª…, top_k=5)
        top3 = parse_recommendation(response)
    except Exception as e:
        print(f"[{idx}] ì—ëŸ¬ ë°œìƒ: {e}")
        top3 = ["ì¶”ì²œ ì‹¤íŒ¨", "ì¶”ì²œ ì‹¤íŒ¨", "ì¶”ì²œ ì‹¤íŒ¨"]

    auto_results.append({
        "ì§ˆì˜": query,
        "í¬í•¨í•µì‹¬ì–´": row["í¬í•¨í•µì‹¬ì–´"],
        "í¬í•¨ê°œìˆ˜": row["í¬í•¨ê°œìˆ˜"],
        "ì¶”ì²œ_ìˆ™ì†Œ1": top3[0],
        "ì¶”ì²œ_ìˆ™ì†Œ2": top3[1],
        "ì¶”ì²œ_ìˆ™ì†Œ3": top3[2]
    })

# âœ… 4. í‰ê°€ ê²°ê³¼ ì €ì¥
result_df = pd.DataFrame(auto_results)
result_df.to_csv("í‰ê°€ê²°ê³¼_ì¶˜ì²œì‹œ_ì§€ì—­í•„í„°2.csv", index=False, encoding="utf-8-sig")
print("âœ… ì €ì¥ ì™„ë£Œ: í‰ê°€ê²°ê³¼_ì¶˜ì²œì‹œ_ì§€ì—­í•„í„°2.csv")